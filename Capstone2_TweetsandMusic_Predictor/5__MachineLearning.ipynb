{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone 2 - Music, Tweets and Language \n",
    "***\n",
    "\n",
    "Music has always been an interest of mine. Personally it helps me be me. I can listen to it to relax, to focus, to work out and so much more. Besides what it can do at a personal level, music has the ability to connect people in ways they may or may not now. Thanks to the ever growing use of social media and technology, these connections are formed even more frequently. For my second capstone, I'm interested in seeing if twitter users with similar music interests can be identified by their tweets. \n",
    "\n",
    "Using previously scraped and cleaned twitter data, I will perform some machine learning to predict genre by text below. See the Scrape Tweets DataWrangle, and EDA notebooks for more information on how I acquired the data and analyzed the data\n",
    "***\n",
    "\n",
    "## Machine Learning\n",
    "\n",
    "Because I have five genres to look at I will be performing multiclass classification using various Machine Learning classifiers and vectorizers to achieve the strongest results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats\n",
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pickle\n",
    "\n",
    "# Import scikit-learn tools, vectorizers, transformer, and classifiers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# import CountVectorizer and TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# import Multinomial Naive Bayes classifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# import Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# import Logistic Regression CV Classifier\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "# import LinearSVC classifier\n",
    "from sklearn.svm import LinearSVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in data\n",
    "with open('data/tweetsML.pickle', 'rb') as b:\n",
    "    tweets = pickle.load(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>tweet</th>\n",
       "      <th>mentions</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>retweet</th>\n",
       "      <th>Genre</th>\n",
       "      <th>word_count</th>\n",
       "      <th>cleaned</th>\n",
       "      <th>genre_cat</th>\n",
       "      <th>emojis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00sarrett</td>\n",
       "      <td>I got 5 others outta the bargain bin but they ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>EDM</td>\n",
       "      <td>19</td>\n",
       "      <td>get outta bargain bin one want add collection ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>00sarrett</td>\n",
       "      <td>I do believe Iâ€™ve determined a suitable replac...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[#forwardthinking]</td>\n",
       "      <td>False</td>\n",
       "      <td>EDM</td>\n",
       "      <td>24</td>\n",
       "      <td>believe determine suitable replacement twa ind...</td>\n",
       "      <td>1</td>\n",
       "      <td>[joy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>00sarrett</td>\n",
       "      <td>Both just started watching and finished The Se...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>EDM</td>\n",
       "      <td>21</td>\n",
       "      <td>start watch finish seven deadly sin anime coup...</td>\n",
       "      <td>1</td>\n",
       "      <td>[100, hearts]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>00sarrett</td>\n",
       "      <td>I got an offer today to move to another state ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[#decisions]</td>\n",
       "      <td>False</td>\n",
       "      <td>EDM</td>\n",
       "      <td>16</td>\n",
       "      <td>get offer today move another state bunk old fr...</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>00sarrett</td>\n",
       "      <td>Roflmao ðŸ˜‚ no doubt haha, this is the extent of...</td>\n",
       "      <td>[gabri_rae]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>EDM</td>\n",
       "      <td>13</td>\n",
       "      <td>roflmao doubt haha extent disagreement ever ac...</td>\n",
       "      <td>1</td>\n",
       "      <td>[joy, 100]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    username                                              tweet     mentions  \\\n",
       "0  00sarrett  I got 5 others outta the bargain bin but they ...           []   \n",
       "1  00sarrett  I do believe Iâ€™ve determined a suitable replac...           []   \n",
       "2  00sarrett  Both just started watching and finished The Se...           []   \n",
       "3  00sarrett  I got an offer today to move to another state ...           []   \n",
       "4  00sarrett  Roflmao ðŸ˜‚ no doubt haha, this is the extent of...  [gabri_rae]   \n",
       "\n",
       "             hashtags  retweet Genre  word_count  \\\n",
       "0                  []    False   EDM          19   \n",
       "1  [#forwardthinking]    False   EDM          24   \n",
       "2                  []    False   EDM          21   \n",
       "3        [#decisions]    False   EDM          16   \n",
       "4                  []    False   EDM          13   \n",
       "\n",
       "                                             cleaned  genre_cat         emojis  \n",
       "0  get outta bargain bin one want add collection ...          1             []  \n",
       "1  believe determine suitable replacement twa ind...          1          [joy]  \n",
       "2  start watch finish seven deadly sin anime coup...          1  [100, hearts]  \n",
       "3  get offer today move another state bunk old fr...          1             []  \n",
       "4  roflmao doubt haha extent disagreement ever ac...          1     [joy, 100]  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets.drop(['username', 'tweet', 'mentions', 'hashtags', 'retweet', 'word_count'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genre</th>\n",
       "      <th>cleaned</th>\n",
       "      <th>genre_cat</th>\n",
       "      <th>emojis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>EDM</td>\n",
       "      <td>get outta bargain bin one want add collection ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>EDM</td>\n",
       "      <td>believe determine suitable replacement twa ind...</td>\n",
       "      <td>1</td>\n",
       "      <td>[joy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>EDM</td>\n",
       "      <td>start watch finish seven deadly sin anime coup...</td>\n",
       "      <td>1</td>\n",
       "      <td>[100, hearts]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>EDM</td>\n",
       "      <td>get offer today move another state bunk old fr...</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>EDM</td>\n",
       "      <td>roflmao doubt haha extent disagreement ever ac...</td>\n",
       "      <td>1</td>\n",
       "      <td>[joy, 100]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Genre                                            cleaned  genre_cat  \\\n",
       "0   EDM  get outta bargain bin one want add collection ...          1   \n",
       "1   EDM  believe determine suitable replacement twa ind...          1   \n",
       "2   EDM  start watch finish seven deadly sin anime coup...          1   \n",
       "3   EDM  get offer today move another state bunk old fr...          1   \n",
       "4   EDM  roflmao doubt haha extent disagreement ever ac...          1   \n",
       "\n",
       "          emojis  \n",
       "0             []  \n",
       "1          [joy]  \n",
       "2  [100, hearts]  \n",
       "3             []  \n",
       "4     [joy, 100]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store tweet dataset into feature matrix and response vector\n",
    "X_words = tweets['cleaned']\n",
    "y_words = tweets['genre_cat']\n",
    "\n",
    "# Instantiate CountVectorizer and TfidfVectorizer\n",
    "count_vect = CountVectorizer(min_df=1, ngram_range=(1, 2)) \n",
    "tfidf_vect = TfidfVectorizer(min_df=1, ngram_range=(1, 2))\n",
    "\n",
    "\n",
    "# Apply CountVectorizer \n",
    "X_count = count_vect.fit_transform(tweets['cleaned'].apply(str))\n",
    "X_count = X_count.tocsc() \n",
    "\n",
    "# Apply TfidfVectorizer\n",
    "X_tfidf = tfidf_vect.fit_transform(tweets['cleaned'].apply(str))\n",
    "X_tfidf = X_tfidf.tocsc()\n",
    "\n",
    "\n",
    "# Split train/test data for all data\n",
    "Xtrain_count, Xtest_count, ytrain_count, ytest_count = train_test_split(X_count, y_words, random_state=17)\n",
    "Xtrain_tfidf, Xtest_tfidf, ytrain_tfidf, ytest_tfidf = train_test_split(X_tfidf, y_words, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(xtest, ytest, clf):\n",
    "    \"\"\" \n",
    "    This function evaluates the effectiveness of a ML model and outputs F1 Scores, AUC score and Confusion Matrix\n",
    "    \"\"\"\n",
    "    # Make predictions for Xtest\n",
    "    y_pred = clf.predict(xtest)\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = metrics.confusion_matrix(ytest, y_pred)\n",
    "    \n",
    "    print(classification_report(ytest, y_pred))\n",
    "    print('\\nConfusion Matrix:\\n', cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate multinomialNB()\n",
    "nb_words_count = MultinomialNB(alpha=1, fit_prior=True)\n",
    "nb_words_tfidf = MultinomialNB(alpha=1, fit_prior=True)\n",
    "\n",
    "# Train model\n",
    "nb_words_count.fit(Xtrain_count, ytrain_count)\n",
    "nb_words_tfidf.fit(Xtrain_tfidf, ytrain_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.59      0.43       361\n",
      "           1       0.45      0.22      0.29       312\n",
      "           2       0.36      0.41      0.38       335\n",
      "           3       0.44      0.20      0.28       278\n",
      "           4       0.36      0.35      0.35       381\n",
      "\n",
      "    accuracy                           0.37      1667\n",
      "   macro avg       0.39      0.36      0.35      1667\n",
      "weighted avg       0.38      0.37      0.35      1667\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[214  23  45  19  60]\n",
      " [109  68  59  21  55]\n",
      " [ 92  23 139  20  61]\n",
      " [ 91  13  58  56  60]\n",
      " [121  25  90  12 133]]\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(Xtest_count, ytest_count, nb_words_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.60      0.42       361\n",
      "           1       0.78      0.08      0.15       312\n",
      "           2       0.27      0.67      0.39       335\n",
      "           3       1.00      0.02      0.04       278\n",
      "           4       0.39      0.15      0.21       381\n",
      "\n",
      "    accuracy                           0.32      1667\n",
      "   macro avg       0.55      0.30      0.24      1667\n",
      "weighted avg       0.53      0.32      0.25      1667\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[215   3 125   0  18]\n",
      " [133  25 133   0  21]\n",
      " [ 86   2 226   0  21]\n",
      " [ 99   1 143   6  29]\n",
      " [125   1 199   0  56]]\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(Xtest_tfidf, ytest_tfidf, nb_words_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both of these results are not that great. It appears that Country music (0) and Hip Hop (2) were the best at being predicted. Let's trying using other models to see if we can get stronger results.\n",
    "\n",
    "***\n",
    "\n",
    "## LogisiticRegressionCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Instantiate and fit training data to Logistic Regression Model (CountVec)\n",
    "log_clf_count = LogisticRegressionCV(scoring='accuracy', \n",
    "                                     class_weight='balanced', \n",
    "                                     cv=5, max_iter=1000).fit(Xtrain_count, ytrain_count)\n",
    "\n",
    "# Instantiate and fit training data to Logistic Regression Model (TFIDF Vec)\n",
    "log_clf_tfidf = LogisticRegressionCV(scoring='accuracy', \n",
    "                                     class_weight='balanced', \n",
    "                                     cv=5, max_iter=1000).fit(Xtrain_tfidf, ytrain_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.42      0.38       361\n",
      "           1       0.32      0.31      0.31       312\n",
      "           2       0.37      0.32      0.35       335\n",
      "           3       0.38      0.20      0.26       278\n",
      "           4       0.31      0.40      0.35       381\n",
      "\n",
      "    accuracy                           0.34      1667\n",
      "   macro avg       0.35      0.33      0.33      1667\n",
      "weighted avg       0.34      0.34      0.33      1667\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[153  61  39  24  84]\n",
      " [ 76  97  40  18  81]\n",
      " [ 70  49 108  26  82]\n",
      " [ 61  31  44  55  87]\n",
      " [ 82  67  58  22 152]]\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(Xtest_count, ytest_count, log_clf_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.34      0.39       361\n",
      "           1       0.61      0.12      0.19       312\n",
      "           2       0.53      0.21      0.30       335\n",
      "           3       0.37      0.14      0.20       278\n",
      "           4       0.27      0.79      0.40       381\n",
      "\n",
      "    accuracy                           0.34      1667\n",
      "   macro avg       0.45      0.32      0.30      1667\n",
      "weighted avg       0.44      0.34      0.31      1667\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[123   8  11  18 201]\n",
      " [ 38  36  15  19 204]\n",
      " [ 37   1  69  16 212]\n",
      " [ 32   4  15  38 189]\n",
      " [ 39  10  20  11 301]]\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(Xtest_tfidf, ytest_tfidf, log_clf_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the performance for Logistic Regression, using a Tfidf vectorizer it does appear to do slightly better than Naive Bayes. F1 Scores for Country, Hip Hop and Metal respectively 0.39, 0.3 and 0.4 respectively. Although this is not high, it is slightly better. Let's continue moving forward.\n",
    "\n",
    "***\n",
    "## Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and fit training data to Random Forest Model (CountVec)\n",
    "forest_clf_count = RandomForestClassifier(class_weight='balanced',\n",
    "                                     n_estimators=100).fit(Xtrain_count, ytrain_count)\n",
    "\n",
    "# Instantiate and fit training data to Random Forest Model (TFIDF Vec)\n",
    "forest_clf_tfidf = RandomForestClassifier(class_weight='balanced',\n",
    "                                     n_estimators=100).fit(Xtrain_tfidf, ytrain_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.44      0.37       361\n",
      "           1       0.37      0.15      0.22       312\n",
      "           2       0.31      0.37      0.34       335\n",
      "           3       0.52      0.14      0.22       278\n",
      "           4       0.27      0.41      0.33       381\n",
      "\n",
      "    accuracy                           0.31      1667\n",
      "   macro avg       0.36      0.30      0.29      1667\n",
      "weighted avg       0.35      0.31      0.30      1667\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[158  28  59  12 104]\n",
      " [ 93  48  65   8  98]\n",
      " [ 81  11 125   9 109]\n",
      " [ 68  11  60  38 101]\n",
      " [ 99  32  88   6 156]]\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(Xtest_count, ytest_count, forest_clf_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.43      0.38       361\n",
      "           1       0.33      0.14      0.20       312\n",
      "           2       0.32      0.39      0.35       335\n",
      "           3       0.44      0.13      0.20       278\n",
      "           4       0.29      0.43      0.35       381\n",
      "\n",
      "    accuracy                           0.32      1667\n",
      "   macro avg       0.34      0.31      0.30      1667\n",
      "weighted avg       0.34      0.32      0.30      1667\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[157  29  58  13 104]\n",
      " [ 90  45  67  13  97]\n",
      " [ 72  16 132  13 102]\n",
      " [ 62  16  68  37  95]\n",
      " [ 93  31  84   8 165]]\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(Xtest_tfidf, ytest_tfidf, forest_clf_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forests appears to be doing the worst in comparison to our other two models. This will be ignored and moved forward.\n",
    "\n",
    "***\n",
    "## LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and fit training data to Random Forest Model (CountVec)\n",
    "svc_count = LinearSVC().fit(Xtrain_count, ytrain_count)\n",
    "\n",
    "# Instantiate and fit training data to Random Forest Model (TFIDF Vec)\n",
    "svc_tfidf = LinearSVC().fit(Xtrain_tfidf, ytrain_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.39      0.38       361\n",
      "           1       0.35      0.28      0.31       312\n",
      "           2       0.34      0.35      0.35       335\n",
      "           3       0.37      0.23      0.28       278\n",
      "           4       0.30      0.42      0.35       381\n",
      "\n",
      "    accuracy                           0.34      1667\n",
      "   macro avg       0.35      0.33      0.34      1667\n",
      "weighted avg       0.35      0.34      0.34      1667\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[141  45  49  25 101]\n",
      " [ 59  86  56  27  84]\n",
      " [ 56  34 118  28  99]\n",
      " [ 51  28  50  64  85]\n",
      " [ 69  51  70  30 161]]\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(Xtest_count, ytest_count, svc_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.67      0.41       361\n",
      "           1       0.32      0.23      0.27       312\n",
      "           2       0.40      0.33      0.36       335\n",
      "           3       0.37      0.21      0.27       278\n",
      "           4       0.40      0.21      0.27       381\n",
      "\n",
      "    accuracy                           0.34      1667\n",
      "   macro avg       0.36      0.33      0.32      1667\n",
      "weighted avg       0.36      0.34      0.32      1667\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[241  42  25  21  32]\n",
      " [146  73  37  26  30]\n",
      " [129  38 109  30  29]\n",
      " [122  24  48  58  26]\n",
      " [176  53  51  22  79]]\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(Xtest_count, ytest_count, svc_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In my opinion LinearSVC perormed the best when using a CountVectorizer. With an overall accuracy of 0.34, F1 scores steadily remained between .28 to .38 across the genres of music."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Next Steps:\n",
    "Taking on the task to tackle classifying individuals by their tweets was very ambitious. To add on the factor of removing the topic, music, from the tweets prior to classifying only added another layer of complexity. From exploring the data I realized early on that there aren't many distinguising differences between people that I had scraped on Twitter after you remove the tweets that separate them into their respective musical genres. However I was able to achieve 0.34 accuracy using a LinearSVC model, which I'm sure can be improved signficantly in the future taking the following steps.\n",
    "\n",
    "1. Spending more time text preprocessing. A lot of tweets had slang terms, broken grammar and english and shortened out words that may have misaligned the total weights when using vectorizers or predictive features. \n",
    "2. People listen to a lot of different music. Just because they say they listen to one doesn't necessarily mean they are only listening to that. It would be important to find respondents that are spending a majority (>70%) of their music listening time in a specific genre.\n",
    "3. Considering using larger text chunks. With the limitation to tweets being only 140 characters, it may not be enough to really distinguish one section of words from another.\n",
    "\n",
    "This would be very useful to many marketing sectors as it would unleash the potential to target individuals by their preferences based on their virtual messages and the patterns they relate to among other individuals.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
