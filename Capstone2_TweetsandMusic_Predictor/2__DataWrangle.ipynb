{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone 2 - Music, Tweets and Language \n",
    "***\n",
    "\n",
    "Music has always been an interest of mine. Personally it helps me be me. I can listen to it to relax, to focus, to work out and so much more. Besides what it can do at a personal level, music has the ability to connect people in ways they may or may not now. Thanks to the ever growing use of social media and technology, these connections are formed even more frequently. For my second capstone, I'm interested in seeing if twitter users with similar music interests can be identified by their tweets. Previously I scraped 40,000 tweets from 1000 different twitter users. \n",
    "***\n",
    "\n",
    "## Data Wrangling\n",
    "\n",
    "Music is differentiated by artists, slang, songs, albums, etc. that can make it very easy to identify what type of music that a user enjoys listening to. For this reason, I want to remove any tweets associated or related to music and focus on the tweets left behind. In addition I want to avoid tweets with only emojis, or only one of two words. \n",
    "\n",
    "To accomplish this task, I had to use beginner and advanced NLP techniques using spaCy, an open source library for Natural Language Processing. More specifically I had to use the technique known as semantic similarity. I go more into this later in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import pandas as pd\n",
    "import json \n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "import itertools\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTIONS\n",
    "\n",
    "# Emoji Conversion Function\n",
    "def convert_emoji(df):\n",
    "    \"\"\" Iterate through each tweet in the dataframe and convert any emojis to a more readable format.\"\"\"\n",
    "    for index, val in enumerate(df.tweet):\n",
    "        df['tweet'].iloc[index] = val.encode('unicode-escape').decode('ASCII')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "hiphop_tweets = pd.read_json('data/hiphoptweets.json', lines=True)\n",
    "country_tweets = pd.read_json('data/countrytweets.json', lines=True)\n",
    "jazz_tweets = pd.read_json('data/jazztweets.json', lines=True)\n",
    "metal_tweets = pd.read_json('data/metaltweets.json', lines=True)\n",
    "edm_tweets = pd.read_json('data/edmtweets.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>timezone</th>\n",
       "      <th>user_id</th>\n",
       "      <th>username</th>\n",
       "      <th>name</th>\n",
       "      <th>place</th>\n",
       "      <th>...</th>\n",
       "      <th>quote_url</th>\n",
       "      <th>video</th>\n",
       "      <th>near</th>\n",
       "      <th>geo</th>\n",
       "      <th>source</th>\n",
       "      <th>user_rt_id</th>\n",
       "      <th>user_rt</th>\n",
       "      <th>retweet_id</th>\n",
       "      <th>reply_to</th>\n",
       "      <th>retweet_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1185396204483555330</td>\n",
       "      <td>1185212741902057472</td>\n",
       "      <td>2019-10-19 03:24:13</td>\n",
       "      <td>2019-10-18</td>\n",
       "      <td>20:24:13</td>\n",
       "      <td>PST</td>\n",
       "      <td>1304920938</td>\n",
       "      <td>waxxgordon</td>\n",
       "      <td>Waxx Gordon</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[{'user_id': '1304920938', 'username': 'WaxXGo...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1177041754371035136</td>\n",
       "      <td>1177037133552508928</td>\n",
       "      <td>2019-09-26 02:06:37</td>\n",
       "      <td>2019-09-25</td>\n",
       "      <td>19:06:37</td>\n",
       "      <td>PST</td>\n",
       "      <td>1304920938</td>\n",
       "      <td>waxxgordon</td>\n",
       "      <td>Waxx Gordon</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[{'user_id': '1304920938', 'username': 'WaxXGo...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1176865647709564928</td>\n",
       "      <td>1176613793897558016</td>\n",
       "      <td>2019-09-25 14:26:50</td>\n",
       "      <td>2019-09-25</td>\n",
       "      <td>07:26:50</td>\n",
       "      <td>PST</td>\n",
       "      <td>1304920938</td>\n",
       "      <td>waxxgordon</td>\n",
       "      <td>Waxx Gordon</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[{'user_id': '1304920938', 'username': 'WaxXGo...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1175851777566105600</td>\n",
       "      <td>1175790713755377664</td>\n",
       "      <td>2019-09-22 19:18:04</td>\n",
       "      <td>2019-09-22</td>\n",
       "      <td>12:18:04</td>\n",
       "      <td>PST</td>\n",
       "      <td>1304920938</td>\n",
       "      <td>waxxgordon</td>\n",
       "      <td>Waxx Gordon</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[{'user_id': '1304920938', 'username': 'WaxXGo...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1175118782274199553</td>\n",
       "      <td>1174789269094838272</td>\n",
       "      <td>2019-09-20 18:45:25</td>\n",
       "      <td>2019-09-20</td>\n",
       "      <td>11:45:25</td>\n",
       "      <td>PST</td>\n",
       "      <td>1304920938</td>\n",
       "      <td>waxxgordon</td>\n",
       "      <td>Waxx Gordon</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[{'user_id': '1304920938', 'username': 'WaxXGo...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id      conversation_id          created_at       date  \\\n",
       "0  1185396204483555330  1185212741902057472 2019-10-19 03:24:13 2019-10-18   \n",
       "1  1177041754371035136  1177037133552508928 2019-09-26 02:06:37 2019-09-25   \n",
       "2  1176865647709564928  1176613793897558016 2019-09-25 14:26:50 2019-09-25   \n",
       "3  1175851777566105600  1175790713755377664 2019-09-22 19:18:04 2019-09-22   \n",
       "4  1175118782274199553  1174789269094838272 2019-09-20 18:45:25 2019-09-20   \n",
       "\n",
       "       time timezone     user_id    username         name place  ...  \\\n",
       "0  20:24:13      PST  1304920938  waxxgordon  Waxx Gordon        ...   \n",
       "1  19:06:37      PST  1304920938  waxxgordon  Waxx Gordon        ...   \n",
       "2  07:26:50      PST  1304920938  waxxgordon  Waxx Gordon        ...   \n",
       "3  12:18:04      PST  1304920938  waxxgordon  Waxx Gordon        ...   \n",
       "4  11:45:25      PST  1304920938  waxxgordon  Waxx Gordon        ...   \n",
       "\n",
       "  quote_url video near geo  source  user_rt_id  user_rt retweet_id  \\\n",
       "0               0                                                    \n",
       "1               0                                                    \n",
       "2               0                                                    \n",
       "3               0                                                    \n",
       "4               0                                                    \n",
       "\n",
       "                                            reply_to retweet_date  \n",
       "0  [{'user_id': '1304920938', 'username': 'WaxXGo...               \n",
       "1  [{'user_id': '1304920938', 'username': 'WaxXGo...               \n",
       "2  [{'user_id': '1304920938', 'username': 'WaxXGo...               \n",
       "3  [{'user_id': '1304920938', 'username': 'WaxXGo...               \n",
       "4  [{'user_id': '1304920938', 'username': 'WaxXGo...               \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine one dataframe to see contents of the data\n",
    "hiphop_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Drop unecessary columns\n",
    "cols_to_drop = ['id', 'conversation_id', 'created_at', 'date', 'time', 'timezone',\n",
    "                'user_id', 'name', 'place', 'urls','photos', 'replies_count', 'retweets_count', \n",
    "                'likes_count', 'cashtags', 'link', 'quote_url', 'video', 'near', 'geo','source', \n",
    "                'user_rt_id', 'user_rt', 'retweet_id', 'reply_to', 'retweet_date']\n",
    "\n",
    "hiphop_tweets = hiphop_tweets.drop(cols_to_drop, axis=1)\n",
    "country_tweets = country_tweets.drop(cols_to_drop, axis=1)\n",
    "jazz_tweets = jazz_tweets.drop(cols_to_drop, axis=1)\n",
    "metal_tweets = metal_tweets.drop(cols_to_drop, axis=1)\n",
    "edm_tweets = edm_tweets.drop(cols_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Genre Column to identify tweets\n",
    "hiphop_tweets['Genre'] = 'Hip-Hop'\n",
    "country_tweets['Genre'] = 'Country' \n",
    "jazz_tweets['Genre'] = 'Jazz'\n",
    "metal_tweets['Genre'] = 'Metal Rock'\n",
    "edm_tweets['Genre'] = 'EDM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat dataframes of tweets together\n",
    "all_tweets = pd.concat([hiphop_tweets, country_tweets, jazz_tweets, metal_tweets, edm_tweets], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Word Embeddings & Semantic Similarity \n",
    "My goal was to remove any tweets related to music but that can be very tricky.\n",
    "1. Looking through 40,000 tweets would be very time consuming.\n",
    "2. I may miss a term within a genre that I am unfamiliar with. For example, Kanye West can be seen referred as Kanye, Yeezus, Ye, Kanye West, etc. \n",
    "3. Building on this even more, an album name can have words that are not correlated to music in any way. Building off the Kanye example, his new album is called \"Jesus is King\", none of which are words related to music.\n",
    "\n",
    "To attempt to tackle this I decided to use semantic similarity. Using the algorithm word2vec and spaCy's prebuilt word embeddings, I looked at the similarity of a tweet to the three words, \"music\", \"album\" and \"song\". From here if the similarity was higher than 0.5 I removed the entire tweet from the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a word embedding using spaCy for the words \"music\", \"album\", and \"song\"\n",
    "music = nlp('music album song')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore UserWarnings for tweets that are only emojis\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "\n",
    "\n",
    "# Iterate over each tweet in the dataframe \"all_tweets\" and do the following inside\n",
    "for i, tweet in enumerate(all_tweets['tweet']):\n",
    "    # Create a word embedding for the current tweet\n",
    "    word_sim = nlp(tweet)\n",
    "    \n",
    "    # If the current tweet is similar to music by more than 0.5 then drop the tweet from the dataframe\n",
    "    if word_sim.similarity(music) > 0.5:\n",
    "        all_tweets.drop(i , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine word count for each tweet\n",
    "all_tweets['word_count'] = all_tweets['tweet'].apply(lambda x: len(str(x).split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop tweets with less than 5 words\n",
    "cleaned_tweets = all_tweets[all_tweets['word_count'] > 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group tweets by word count \n",
    "g = cleaned_tweets.groupby([\"username\"]).apply(lambda x: x.sort_values([\"word_count\"], \n",
    "                                                                       ascending = False)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create final dataframe with top 10 tweets per user\n",
    "final = g.groupby('username').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>tweet</th>\n",
       "      <th>mentions</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>retweet</th>\n",
       "      <th>Genre</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00sarrett</td>\n",
       "      <td>I got 5 others outta the bargain bin but they ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>EDM</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>00sarrett</td>\n",
       "      <td>I do believe Iâ€™ve determined a suitable replac...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[#forwardthinking]</td>\n",
       "      <td>False</td>\n",
       "      <td>EDM</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>00sarrett</td>\n",
       "      <td>Both just started watching and finished The Se...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>EDM</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>00sarrett</td>\n",
       "      <td>I got an offer today to move to another state ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[#decisions]</td>\n",
       "      <td>False</td>\n",
       "      <td>EDM</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>00sarrett</td>\n",
       "      <td>Roflmao ðŸ˜‚ no doubt haha, this is the extent of...</td>\n",
       "      <td>[gabri_rae]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>EDM</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21999</td>\n",
       "      <td>zmaskm</td>\n",
       "      <td>I am just absolutely baffled as to why this wo...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>Metal Rock</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>zmaskm</td>\n",
       "      <td>So hey, Guts in D&amp;D;  VERY high level, definit...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>Metal Rock</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22001</td>\n",
       "      <td>zmaskm</td>\n",
       "      <td>When you really think about it, programming is...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>Metal Rock</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22002</td>\n",
       "      <td>zmaskm</td>\n",
       "      <td>I honestly wouldn't be surprised if we did get...</td>\n",
       "      <td>[ficklampa]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>Metal Rock</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22003</td>\n",
       "      <td>zmaskm</td>\n",
       "      <td>it's hard to find any solid leads on hacks and...</td>\n",
       "      <td>[ficklampa]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>Metal Rock</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8315 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        username                                              tweet  \\\n",
       "0      00sarrett  I got 5 others outta the bargain bin but they ...   \n",
       "1      00sarrett  I do believe Iâ€™ve determined a suitable replac...   \n",
       "2      00sarrett  Both just started watching and finished The Se...   \n",
       "3      00sarrett  I got an offer today to move to another state ...   \n",
       "4      00sarrett  Roflmao ðŸ˜‚ no doubt haha, this is the extent of...   \n",
       "...          ...                                                ...   \n",
       "21999     zmaskm  I am just absolutely baffled as to why this wo...   \n",
       "22000     zmaskm  So hey, Guts in D&D;  VERY high level, definit...   \n",
       "22001     zmaskm  When you really think about it, programming is...   \n",
       "22002     zmaskm  I honestly wouldn't be surprised if we did get...   \n",
       "22003     zmaskm  it's hard to find any solid leads on hacks and...   \n",
       "\n",
       "          mentions            hashtags  retweet       Genre  word_count  \n",
       "0               []                  []    False         EDM          50  \n",
       "1               []  [#forwardthinking]    False         EDM          46  \n",
       "2               []                  []    False         EDM          38  \n",
       "3               []        [#decisions]    False         EDM          28  \n",
       "4      [gabri_rae]                  []    False         EDM          28  \n",
       "...            ...                 ...      ...         ...         ...  \n",
       "21999           []                  []    False  Metal Rock          45  \n",
       "22000           []                  []    False  Metal Rock          37  \n",
       "22001           []                  []    False  Metal Rock          34  \n",
       "22002  [ficklampa]                  []    False  Metal Rock          33  \n",
       "22003  [ficklampa]                  []    False  Metal Rock          32  \n",
       "\n",
       "[8315 rows x 7 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sigitt_iddm        10\n",
       "miss_mina13        10\n",
       "santoscooks        10\n",
       "alec_aandjgoods    10\n",
       "2xtremerko         10\n",
       "                   ..\n",
       "bigbillshater       3\n",
       "avela_rongo         3\n",
       "gustav_aka          2\n",
       "dopedrumkits        1\n",
       "iamrachelv          1\n",
       "Name: username, Length: 839, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final['username'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hip-Hop       1793\n",
       "Metal Rock    1732\n",
       "Jazz          1607\n",
       "EDM           1599\n",
       "Country       1584\n",
       "Name: Genre, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final['Genre'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Export Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_csv('tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_pickle('tweets.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_json('tweets.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
